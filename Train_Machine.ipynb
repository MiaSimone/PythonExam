{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rest_list length: 37\n",
      "x_test_list length: 326\n",
      "x_train_list length: 1288\n",
      "y_test_list length: 326\n"
     ]
    }
   ],
   "source": [
    "main_path = \"/home/jovyan/Exam_Project/Dataset/\"\n",
    "data = os.listdir(main_path)\n",
    "#y_train skal bestå af en liste over hvert billedes kategori nummer\n",
    "#x_train skal bestå af 133 billeder, dvs. en liste med 130 lister i, hver bestående af nogle tuples\n",
    "\n",
    "# Hvert billede består af 784 tuples\n",
    "# Der skal random vælges 13 billeder fra hver kategori til train\n",
    "\n",
    "x_train_list = []\n",
    "y_train_list = []\n",
    "x_test_list = []\n",
    "y_test_list = []\n",
    "\n",
    "for d in data:\n",
    "    path = os.path.join(main_path, d)\n",
    "    # For hver path ligger der en række billeder, dem skal vi have proppet ind i en liste og valgt 13 ud\n",
    "    f = r''+path\n",
    "    \n",
    "    full_file_list = []\n",
    "    for file in os.listdir(f):\n",
    "        full_file_list.append(file)\n",
    "    \n",
    "    train_procent_number = (len(full_file_list)/100)*80\n",
    "    \n",
    "    randomlist = []\n",
    "    randomlist = random.sample(range(0, len(full_file_list)), int(train_procent_number))\n",
    "    full_number_list = list(range(0,len(full_file_list)))\n",
    "    rest_list = full_number_list\n",
    "    \n",
    "    \n",
    "    done_list = []\n",
    "    for ran in randomlist:\n",
    "        for fi in full_number_list:\n",
    "            if ran==fi:\n",
    "                rest_list.remove(ran)\n",
    "        \n",
    "        for file in full_file_list:\n",
    "            if full_file_list.index(file) == ran:\n",
    "                done_list.append(file) # done_list indeholder 13 random billeder pr. kategori\n",
    "   \n",
    "   \n",
    "    # Nu indeholder rest_list de 7 billeder som train ikke indeholder pr. kategori\n",
    "    for r in rest_list:\n",
    "        for file in full_file_list:\n",
    "            if full_file_list.index(file) == r:\n",
    "                f_img = f+\"/\"+file\n",
    "\n",
    "                i = Image.open(f_img).convert('RGBA')\n",
    "\n",
    "                x_test_list.append(np.array(i))\n",
    "                y_test_list.append(data.index(d))\n",
    "    \n",
    "    for done in done_list:\n",
    "        f_img = f+\"/\"+done\n",
    "        \n",
    "        i = Image.open(f_img).convert('RGBA')\n",
    "        \n",
    "        x_train_list.append(np.array(i))\n",
    "        y_train_list.append(data.index(d))\n",
    "\n",
    "print(\"rest_list length: \" + str(len(rest_list)))\n",
    "print(\"x_test_list length: \" + str(len(x_test_list)))\n",
    "print(\"x_train_list length: \" + str(len(x_train_list)))\n",
    "print(\"y_test_list length: \" + str(len(y_test_list)))\n",
    "x_train = np.array(x_train_list)\n",
    "x_test = np.array(x_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1288, 200, 200, 4)\n",
      "<class 'numpy.ndarray'>\n",
      "(326, 200, 200, 4)\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train))\n",
    "print(x_train.shape)\n",
    "print(type(x_test))\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train before: \n",
      "(1288,)\n",
      "y_train after: \n",
      "(1288, 10)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 198, 198, 32)      1184      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 97, 97, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 46, 46, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 135424)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                8667200   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 8,724,458\n",
      "Trainable params: 8,724,458\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "y_train = np.array(y_train_list)\n",
    "x_test = np.array(x_test_list)\n",
    "y_test = np.array(y_test_list)\n",
    "print(\"y_train before: \")\n",
    "print(y_train.shape)\n",
    "training_data = (x_train, y_train)\n",
    "test_data = (x_test, y_test)\n",
    "\n",
    "#reformat output\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "print(\"y_train after: \")\n",
    "print(y_train.shape)\n",
    "\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=x_train.shape[1:]))\n",
    "model.add(layers.MaxPool2D((2,2))) # Max Pooling to reduce the spatial dimensions of the output volume. pool_size: integer or tuple of 2 integers, factors by which to downscale (vertical, horizontal)\n",
    "model.add(layers.Conv2D(64,(3,3),activation='relu')) # does not need input_shape, since it gets it from previous layer\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(layers.Flatten()) # rewrite tensor to single vector of values\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax')) # softmax is good for output layer because Softmax outputs probabilities range. The range will 0 to 1, and the sum of all the probabilities will be equal to one. If the softmax function used for multi-classification model it returns the probabilities of each class and the target class will have the high probability.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "19/19 [==============================] - 77s 3s/step - loss: 984.9740 - accuracy: 0.0994 - val_loss: 3.6167 - val_accuracy: 0.1163\n",
      "Epoch 2/5\n",
      "19/19 [==============================] - 55s 3s/step - loss: 2.1036 - accuracy: 0.2977 - val_loss: 4.2892 - val_accuracy: 0.0233\n",
      "Epoch 3/5\n",
      "19/19 [==============================] - 52s 3s/step - loss: 22.8744 - accuracy: 0.3814 - val_loss: 3.5981 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "19/19 [==============================] - 52s 3s/step - loss: 2.1947 - accuracy: 0.3008 - val_loss: 3.7679 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "19/19 [==============================] - 57s 3s/step - loss: 2.1343 - accuracy: 0.3053 - val_loss: 4.2010 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f80562eb4d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', # loss is how to meassure how wrong the model is on its predictions\n",
    "             optimizer='rmsprop', # \"stochastic gradient descent\" is a way to tell algorithm how to improve\n",
    "             metrics=['accuracy'], # what do we care about in our model\n",
    "             )\n",
    "\n",
    "model.fit(x_train,\n",
    "         y_train,\n",
    "         epochs=5,\n",
    "         verbose=True,\n",
    "         batch_size=64,\n",
    "         validation_split=0.1) # checking periodically how well we are doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326\n",
      "326\n",
      "(326, 200, 200, 4)\n",
      "(326, 10)\n",
      "11/11 [==============================] - 4s 318ms/step - loss: 2.4645 - accuracy: 0.1963\n",
      "test loss, test acc: [2.4644527435302734, 0.19631901383399963]\n",
      "\n",
      "# Generate predictions for 3 samples\n",
      "[2 7 7 2 2 2 2 6 2 6 6 2 2 6 2 2 2 2 2 6 2 2 2 2 2 6 2 2 2 6 1 6 7 2 2 2 2\n",
      " 2 1 2 2 7 2 7 6 2 2 2 2 2 2 2 2 2 2 2 2 2 7 2 2 2 2 2 2 2 7 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 7 2 6 2 2 2 2 2 2 2 2 2 2 7 7 2 2 2 2 7 7 2 6 2 7 2\n",
      " 2 2 2 6 2 6 2 2 7 2 7 2 7 7 2 2 2 2 2 2 2 2 2 2 7 7 2 2 2 2 2 2 2 2 2 7 2\n",
      " 2 7 2 2 2 2 2 2 2 6 2 7 6 7 2 2 2 2 2 2 2 2 2 7 2 7 2 7 2 6 6 2 2 2 1 7 2\n",
      " 2 5 2 6 2 2 2 2 2 2 2 2 2 2 2 2 2 5 2 2 2 7 7 2 2 2 2 2 2 7 2 6 2 7 7 2 7\n",
      " 1 2 2 7 6 7 7 7 2 2 2 7 7 6 7 7 2 7 1 2 2 2 2 2 2 7 2 7 7 6 7 2 7 7 7 2 7\n",
      " 2 2 2 7 7 7 7 7 2 7 7 2 2 7 7 7 2 7 2 7 7 2 7 2 2 6 7 7 2 7 7 2 7 2 7 7 2\n",
      " 7 2 7 7 2 2 6 7 6 7 7 2 7 2 2 2 2 6 2 2 7 2 2 4 7 2 6 4 7 2]\n",
      "predict classes [2 7 7]\n",
      "actual:\n",
      " [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(len(x_test))\n",
    "print(len(y_test))\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print('test loss, test acc:', results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print('\\n# Generate predictions for 3 samples')\n",
    "predictions = np.argmax(model.predict(x_test), axis=-1)\n",
    "#predictions = model.predict(x_test[:3])\n",
    "print(predictions)\n",
    "print('predict classes',model.predict_classes(x_test[:3]))\n",
    "print('actual:\\n',y_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
